<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>MLE 2023 - 6&nbsp; Binary Dependent Variables</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./07-QuantitiesofInterest.html" rel="next">
<link href="./05-IntrotoMaximumLikelihood.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./06-BinaryOutcomes.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Binary Dependent Variables</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MLE 2023</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Maxmimum Likelihood Fall 2023</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-ROverview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">R Overview</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-TheMATH.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Math</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-ReviewofOLS.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Review of OLS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-IntrotoMaximumLikelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to MLE</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-BinaryOutcomes.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Binary Dependent Variables</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-QuantitiesofInterest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Quantities of Interest</span></span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Section Contents</h2>
   
  <ul>
  <li><a href="#data-generating-process" id="toc-data-generating-process" class="nav-link active" data-scroll-target="#data-generating-process"><span class="header-section-number">6.1</span> Data Generating Process</a>
  <ul>
  <li><a href="#mle-estimation" id="toc-mle-estimation" class="nav-link" data-scroll-target="#mle-estimation"><span class="header-section-number">6.1.1</span> MLE Estimation</a></li>
  </ul></li>
  <li><a href="#r-code-for-fitting-logistic-regression" id="toc-r-code-for-fitting-logistic-regression" class="nav-link" data-scroll-target="#r-code-for-fitting-logistic-regression"><span class="header-section-number">6.2</span> R code for fitting logistic regression</a>
  <ul>
  <li><a href="#writing-down-the-regression-model" id="toc-writing-down-the-regression-model" class="nav-link" data-scroll-target="#writing-down-the-regression-model"><span class="header-section-number">6.2.1</span> Writing down the regression model</a></li>
  </ul></li>
  <li><a href="#probit-regression" id="toc-probit-regression" class="nav-link" data-scroll-target="#probit-regression"><span class="header-section-number">6.3</span> Probit Regression</a></li>
  <li><a href="#to-logit-or-to-probit" id="toc-to-logit-or-to-probit" class="nav-link" data-scroll-target="#to-logit-or-to-probit"><span class="header-section-number">6.4</span> To logit or to probit?</a></li>
  <li><a href="#latent-propensity-representation" id="toc-latent-propensity-representation" class="nav-link" data-scroll-target="#latent-propensity-representation"><span class="header-section-number">6.5</span> Latent propensity representation</a></li>
  <li><a href="#linear-probability-models" id="toc-linear-probability-models" class="nav-link" data-scroll-target="#linear-probability-models"><span class="header-section-number">6.6</span> Linear Probability Models</a></li>
  <li><a href="#binary-models-in-r-tutorial" id="toc-binary-models-in-r-tutorial" class="nav-link" data-scroll-target="#binary-models-in-r-tutorial"><span class="header-section-number">6.7</span> Binary Models in R Tutorial</a>
  <ul>
  <li><a href="#loading-data-and-fitting-glm" id="toc-loading-data-and-fitting-glm" class="nav-link" data-scroll-target="#loading-data-and-fitting-glm"><span class="header-section-number">6.7.1</span> Loading data and fitting glm</a></li>
  <li><a href="#numeric-optimization" id="toc-numeric-optimization" class="nav-link" data-scroll-target="#numeric-optimization"><span class="header-section-number">6.7.2</span> Numeric Optimization</a></li>
  <li><a href="#predicted-probabilities" id="toc-predicted-probabilities" class="nav-link" data-scroll-target="#predicted-probabilities"><span class="header-section-number">6.7.3</span> Predicted Probabilities</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="binary" class="quarto-section-identifier"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Binary Dependent Variables</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<script src="https://hypothes.is/embed.js" async=""></script>
<p>In this section, we review models specifically designed for estimating the relationships between our independent variables and a dichotomous dependent variable. This is where “logit” and “probit” regression models become relevant.</p>
<p><strong>Resources</strong></p>
<p>These concepts are discussed in King, Gary. 1998. <em>Unifying political methodology: The likelihood theory of statistical inference.</em> University of Michigan Press. 5.1-5.3 (available through Rutgers online library)</p>
<p>The 2020 Gelman et al.&nbsp;book referenced in the syllabus also has a chapter devoted to logistic regression.</p>
<p>Key limitations of OLS in the binary case are discussed <a href="https://www.dummies.com/education/economics/econometrics/3-main-linear-probability-model-lpm-problems/">here</a>, and will be referenced at the end of the section.</p>
<section id="data-generating-process" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="data-generating-process"><span class="header-section-number">6.1</span> Data Generating Process</h2>
<p>Let’s say <span class="math inline">\(Y_i\)</span> is a set of 0’s and 1’s for whether two states have experienced a dispute, an outcome common in IR studies.</p>
<span class="math display">\[\begin{gather*}
Y_i = \begin{cases}1, \;\text{a dispute happened}\\ 0,\;
\text{a dispute did not happen}\end{cases}
\end{gather*}\]</span>
<ul>
<li>Outside of political science, for example, in the field of higher education, we might instead think about an outcome related to whether a student has (= 1) or has not (= 0) had a negative advising experience.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of first 20 observations (Y1, Y2, ..., Y20)</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="dv">0</span> <span class="dv">1</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">0</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We need to align these data with a data generating process and distribution.</p>
<ul>
<li>For each <span class="math inline">\(Y_i\)</span>, it is like a single trial, where you have a dispute with some probability <span class="math inline">\((\pi)\)</span>
<ul>
<li>This sounds like the Bernoulli distribution! <span class="math inline">\(Y_i \sim Bernouli(\pi)\)</span></li>
</ul></li>
</ul>
<section id="mle-estimation" class="level3" data-number="6.1.1">
<h3 data-number="6.1.1" class="anchored" data-anchor-id="mle-estimation"><span class="header-section-number">6.1.1</span> MLE Estimation</h3>
<p>Let’s do the steps we saw in the previous section.</p>
<ol type="1">
<li><p><strong><em>What is the data generating process?</em></strong> Based on this, describe the probability distribution for <span class="math inline">\(Y_i\)</span>.</p>
<ul>
<li>Note: if you are using a function like <code>glm()</code> you can proceed directly there after this step. However, let’s work under the hood for a bit.</li>
</ul>
<p><span class="math display">\[\begin{align*}
Y_i \sim f(Y_i | \pi) &amp;= Pr(Y_i = y_i |\pi_i) = \underbrace{\pi^{y_i}(1 -\pi)^{(1-y_i)}}_\text{pmf for Bernoulli}
\end{align*}\]</span> for <span class="math inline">\(y = 0,1\)</span></p></li>
<li><p><strong><em>Define the likelihood for a single observation</em></strong></p></li>
<li><p><strong><em>Define the likelihood for all observations</em></strong></p></li>
<li><p><strong><em>Find the log-likelihood</em></strong></p></li>
</ol>
<span class="math display">\[\begin{align*}
\mathcal L( \pi | Y_i) &amp;= \underbrace{\pi^{y_i}(1 -\pi)^{(1-y_i)}}_\text{Likelihood for single observation}\\
\mathcal L( \pi | Y) &amp;= \underbrace{\prod_{i=1}^n\pi^{y_i}(1 -\pi)^{(1-y_i)}}_\text{Likelihood for all observations}\\
\ell( \pi | Y) &amp;= \underbrace{\sum_{i=1}^n\log \pi^{y_i}(1 -\pi)^{(1-y_i)}}_\text{Log likelihood}\\
\hat \pi &amp;= \text{Next step: arg max } \ell( \pi | Y) \text{ wrt $\pi$}
\end{align*}\]</span>
<p><strong><em>Add step: nonlinear transformation to</em></strong> <span class="math inline">\(X\beta\)</span></p>
<ul>
<li><p>Note that because we are likely using covariates, we need to express our parameter as a function of <span class="math inline">\(X\beta\)</span>. Why? Because we don’t think there is a constant probability for a dispute. Instead, we think the probability of a dispute varies according to different independent variables, which are included in the <span class="math inline">\(X\)</span> matrix and everntually will each have their own <span class="math inline">\(\beta_k\)</span> relationship with the probability of dispute.</p>
<ul>
<li>Now that we are outside of linear territory, we cannot just simply replace <span class="math inline">\(\pi\)</span> with <span class="math inline">\(X\beta\)</span> in the equation. Instead, <span class="math inline">\(\pi\)</span> is a function of <span class="math inline">\(X\beta\)</span>. <span class="math inline">\(\pi = g(X_i, \beta) \neq \mathbf{x}_i'\beta\)</span></li>
</ul></li>
<li><p>This is because we need a transformation, such as the logit or probit to map our linear predictor into the outcome to make sure the linear predictor can be transformed back into sensible units of the outcome. The logit is one variety, as is the probit. Like two roads diverged in a yellow wood, this is the point in the process where we choose the transformation. For this first example, let’s apply a logit transformation, which restricts our estimates to between 0 and 1 (a good thing for probability!) where:</p></li>
<li><p><span class="math inline">\(\pi_i = \text{logit}^{-1}(\eta_i) = \frac{exp^{\eta_i}}{1 + exp^{\eta_i}} = \frac{exp^{\mathbf{x}_i'\beta}}{1 + exp^{\mathbf{x}_i'\beta}}\)</span></p></li>
<li><p><span class="math inline">\(\eta_i = \text{logit}(\pi_i) = \log\frac{\pi_i}{1-\pi_i} = \mathbf{x}_i'\beta\)</span></p></li>
</ul>
<ol start="5" type="1">
<li><strong><em>Maximize the function with respect to (wrt)</em></strong> <span class="math inline">\(\theta\)</span></li>
</ol>
<p>Where <span class="math inline">\(\pi_i = \frac{exp^{\mathbf{x}_i'\beta}}{1 + exp^{\mathbf{x}_i'\beta}}\)</span></p>
<span class="math display">\[\begin{align*}
\hat \pi &amp;= \text{arg max } \ell( \pi | Y) \text{ wrt $\pi$} \\
&amp;= \text{arg max} \sum_{i=1}^n\log \pi_i^{y_i}(1 -\pi_i)^{(1-y_i)}\\
&amp;= \text{arg max} \sum_{i=1}^n \underbrace{y_i \log \Big( \frac{exp^{\mathbf{x}_i'\beta}}{1 + exp^{\mathbf{x}_i'\beta}}\Big) + (1-y_i)\log \Big(1-\frac{exp^{\mathbf{x}_i'\beta}}{1 + exp^{\mathbf{x}_i'\beta}}\Big)}_\text{We replaced $\pi_i$ and used the rule $\log a^b = b \log a$ to bring down the $y_i$ terms.}
\end{align*}\]</span>
<p>At this point, we take the derivative with respect to <span class="math inline">\(\beta\)</span>. You can try this on your own, and, if you’re lucky, it may show up on a problem set near you. With a bit of work, we should get something that looks like the below, which we can represent in terms of a sum or in matrix notation.</p>
<span class="math display">\[\begin{align*}
S(\theta) &amp;=  \sum_{i=1}^n (Y_i - \pi_i)\mathbf{x}^T_i\\
&amp;= X^T(Y - \mathbf{\pi})
\end{align*}\]</span>
<p><em>You can note that the matrix notation retains the dimensions</em> <span class="math inline">\(k \times 1\)</span>, which we would expect because we want to choose a set of <span class="math inline">\(k\)</span> coefficients in our <span class="math inline">\(k \times 1\)</span> vector <span class="math inline">\(\beta\)</span>. The score, as written in summation notation, also has length <span class="math inline">\(k\)</span> but here, we use a convention as writing <span class="math inline">\(\mathbf{x}_i'\)</span> in row vector representation instead of a column vector. You could instead represent this as multiplied by <span class="math inline">\(\mathbf{x}_i\)</span>, which would give us the <span class="math inline">\(k \times 1\)</span> dimensions. Either way we have <span class="math inline">\(k\)</span> coefficients. These are just different notations.</p>
<ol start="6" type="1">
<li>Take the second derivative of the log likelihood to get the “hessian” and help estimate the uncertainty of the estimates. Again, we can represent this as a sum or in matrix notation, which might be easier when translating this into R code where our data is more naturally inside a matrix.</li>
</ol>
<p><span class="math display">\[\begin{align*}
H(\theta) &amp;=  - \sum_{i=1}^n \mathbf{x}_i\mathbf{x}^T_i(\pi_i)(1 - \pi_i)\\
&amp;= -X^TVX
\end{align*}\]</span> where <span class="math inline">\(V\)</span> is <span class="math inline">\(n \times n\)</span> diagonal matrix with weights that are the ith element of <span class="math inline">\((\pi)(1 - \pi)\)</span></p>
<p>Once we have these quantities, we can optimize the function with an algorithm or go to <code>glm</code> in R, which will do that for us.</p>
</section>
</section>
<section id="r-code-for-fitting-logistic-regression" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="r-code-for-fitting-logistic-regression"><span class="header-section-number">6.2</span> R code for fitting logistic regression</h2>
<p>We can fit logistic regressions in R through <code>glm()</code>. Let’s build on the ANES example from section 5.3 and analyze a dichotomized measure of participation where 1=participated in at least some form and 0=did not participate.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>anes <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"https://raw.githubusercontent.com/ktmccabe/teachingdata/main/anesdems.csv"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>anes<span class="sc">$</span>partbinary <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(anes<span class="sc">$</span>participation <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can then fit using <code>glm</code> where <code>family = binomial(link="logit")</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>out.logit <span class="ot">&lt;-</span> <span class="fu">glm</span>(partbinary <span class="sc">~</span> female <span class="sc">+</span> edu <span class="sc">+</span> age <span class="sc">+</span> sexism, <span class="at">data=</span>anes,</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link=</span><span class="st">"logit"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The summary output includes the logit coefficients, standard errors, z-scores, and p-values.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(out.logit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = partbinary ~ female + edu + age + sexism, family = binomial(link = "logit"), 
    data = anes)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.5668   0.3328   0.4475   0.6287   1.2936  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  1.016734   0.334656   3.038  0.00238 ** 
female      -0.382087   0.151516  -2.522  0.01168 *  
edu          0.321190   0.050945   6.305 2.89e-10 ***
age          0.008682   0.004046   2.146  0.03188 *  
sexism      -1.593694   0.336373  -4.738 2.16e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1361.5  on 1584  degrees of freedom
Residual deviance: 1252.9  on 1580  degrees of freedom
  (355 observations deleted due to missingness)
AIC: 1262.9

Number of Fisher Scoring iterations: 5</code></pre>
</div>
</div>
<section id="writing-down-the-regression-model" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="writing-down-the-regression-model"><span class="header-section-number">6.2.1</span> Writing down the regression model</h3>
<p>In the articles you write, you will describe the methods you use in detail, including the variables in the model and the type of regression (e.g., logistic regression). Sometimes you may want to go a step further and be very explicit about the model that you ran. We’ve already seen the regression equations for linear models. For the GLMs, they will look very similar, but we need to make the link/response function an explicit part of the equation.</p>
<p>For example, for logistic regression we have a few ways of writing it, including:</p>
<ul>
<li><span class="math inline">\(\log \frac{\pi_i}{1-\pi_i} = \mathbf{x_i'}\beta\)</span>, or alternatively</li>
<li><span class="math inline">\(Pr(Y_i = 1 | \mathbf{x}_i) = logit^{-1}(\mathbf{x}_i'\beta) = \frac{exp(\mathbf{x_i'}\beta)}{(1 + exp(\mathbf{x_i'}\beta)}\)</span></li>
</ul>
<p>(You can also write out the individual variable names.) There is a new R package <a href="https://github.com/datalorax/equatiomatic">equatiomatic</a> that can also be used to help write the equations from regression models. It’s not perfect, but should get you there for most basic models.</p>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="do">## First time, you need to install one of these</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">#remotes::install_github("datalorax/equatiomatic")</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages("equatiomatic")</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Each time after, run library</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(equatiomatic)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Will output in latex code, though see package for details on options</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="fu">extract_eq</span>(out.logit, <span class="at">wrap =</span> <span class="cn">TRUE</span>, <span class="at">terms_per_line =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><span class="math display">\[
\begin{aligned}
\log\left[ \frac { P( \operatorname{partbinary} = \operatorname{1} ) }{ 1 - P( \operatorname{partbinary} = \operatorname{1} ) } \right] &amp;= \alpha + \beta_{1}(\operatorname{female}) + \beta_{2}(\operatorname{edu})\ + \\
&amp;\quad \beta_{3}(\operatorname{age}) + \beta_{4}(\operatorname{sexism})
\end{aligned}
\]</span></p>
</div>
</section>
</section>
<section id="probit-regression" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="probit-regression"><span class="header-section-number">6.3</span> Probit Regression</h2>
<p>Probit regression is very similar to logit except we use a different link function to map the linear predictor into the outcome. Both the logit and probit links are suitable for binary outcomes with a Bernoulli distribution. If we apply a probit transformation, this also restricts our estimates to between 0 and 1.</p>
<ul>
<li><span class="math inline">\(\pi_i = Pr(Y_i = 1| X_i) = \Phi(\mathbf{x}_i'\beta)\)</span></li>
<li><span class="math inline">\(\eta_i = \Phi^{-1}(\pi_i) = \mathbf{x}_i'\beta\)</span></li>
</ul>
<p>Here, our coefficients <span class="math inline">\(\hat \beta\)</span> represent changes in “probits” or changes “z-score” units. We use the Normal CDF (<span class="math inline">\(\Phi()\)</span>) aka <code>pnorm()</code> in R to transform them back into probabilities, specifically, the probability that <span class="math inline">\(Y_i\)</span> is 1.</p>
<p>Let’s fit our binary model with probit. We just need to change the link function.</p>
<p>We can then fit using <code>glm</code> where <code>family = binomial(link="probit")</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>out.probit <span class="ot">&lt;-</span> <span class="fu">glm</span>(partbinary <span class="sc">~</span> female <span class="sc">+</span> edu <span class="sc">+</span> age <span class="sc">+</span> sexism, <span class="at">data=</span>anes,</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link=</span><span class="st">"probit"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s apply the equation tool to this:</p>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Each time after, run library</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(equatiomatic)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Will output in latex code, though see package for details on options</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="fu">extract_eq</span>(out.probit, <span class="at">wrap =</span> <span class="cn">TRUE</span>, <span class="at">terms_per_line =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><span class="math display">\[
\begin{aligned}
P( \operatorname{partbinary} = \operatorname{1} ) &amp;= \Phi[\alpha + \beta_{1}(\operatorname{female}) + \beta_{2}(\operatorname{edu})\ + \\
&amp;\qquad\ \beta_{3}(\operatorname{age}) + \beta_{4}(\operatorname{sexism})]
\end{aligned}
\]</span></p>
</div>
<p>The summary output includes the probit coefficients, standard errors, z-scores, and p-values.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(out.probit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = partbinary ~ female + edu + age + sexism, family = binomial(link = "probit"), 
    data = anes)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.6343   0.3188   0.4470   0.6361   1.2477  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  0.603661   0.184864   3.265  0.00109 ** 
female      -0.202300   0.083407  -2.425  0.01529 *  
edu          0.179264   0.027611   6.493 8.44e-11 ***
age          0.005145   0.002257   2.280  0.02261 *  
sexism      -0.898871   0.186443  -4.821 1.43e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1361.5  on 1584  degrees of freedom
Residual deviance: 1250.6  on 1580  degrees of freedom
  (355 observations deleted due to missingness)
AIC: 1260.6

Number of Fisher Scoring iterations: 5</code></pre>
</div>
</div>
<p>We can interepret the sign and significance of the coefficients similarly to OLS. They just aren’t in units of <span class="math inline">\(Y\)</span>. In the section next week, we will discuss in detail how to generate quantities of interest from this output.</p>
</section>
<section id="to-logit-or-to-probit" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="to-logit-or-to-probit"><span class="header-section-number">6.4</span> To logit or to probit?</h2>
<p>Both approaches produce a monotonically increasing S-curve in probability between 0 and 1, which vary according to the linear predictor (<span class="math inline">\(\mathbf{x_i}^T\beta\)</span>). In this way, either approach satisfies the need to keep our estimates, when transformed, within the plausible range of <span class="math inline">\(Y\)</span>.</p>
<p><img src="images/logitprobit.png" class="img-fluid" style="width:50.0%"> <em>Image from Kosuke Imai.</em></p>
<ul>
<li>Both also start with <span class="math inline">\(Y_i\)</span> as bernoulli</li>
<li>Both produce the same function of the log-likelihood BUT define <span class="math inline">\(\pi_i\)</span> and link function differently</li>
<li>Results–in terms of sign and significance of coefficients– are very similar
<ul>
<li>Logit coefficients are roughly 1.6*probit coefficients</li>
</ul></li>
<li>Results–in terms of predicted probabilities– are very similar
<ul>
<li>Exception– at extreme probabilities– Logit has “thicker tails”, gets to 0 and 1 more slowly</li>
</ul></li>
<li>Sometimes useful–Logit can also be transformed into “odds ratios”</li>
<li>By convention, logit slightly more typically used in political science but easy enough to find examples of either</li>
</ul>
<p><strong><em>Note on Odds Ratios in Logistic Regression</em></strong></p>
<p>Coefficients are in “logits” or changes in “log-odds” (<span class="math inline">\(\log \frac{\pi_i}{1 - \pi}\)</span>). Some disciplines like to report “odds ratios”</p>
<ul>
<li>Odds ratio: <span class="math inline">\(\frac{\pi_i(x1)/(1 - \pi(x1))}{\pi_i(x0)/(1 - \pi(x0))}\)</span> (at a value of x1 vs.&nbsp;x0)
<ul>
<li>If <span class="math inline">\(\log \frac{\pi_i}{1 - \pi} = logodds\)</span>; <span class="math inline">\(\exp(logodds) = \frac{\pi_i}{1 - \pi}\)</span></li>
<li>Therefore, if we exponentiate our coefficients, this represents an odds ratio: the odds of <span class="math inline">\(Y_i = 1\)</span> increase by a factor of (<span class="math inline">\(\exp(\hat \beta_k)\)</span>) due to 1-unit change in X</li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="do">## odds ratio for the 4th coefficient</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">coef</span>(out.logit)[<span class="dv">4</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    age 
1.00872 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="do">## CI for odds ratios</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="fu">confint</span>(out.logit)[<span class="dv">4</span>, ])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Waiting for profiling to be done...</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>   2.5 %   97.5 % 
1.000790 1.016801 </code></pre>
</div>
</div>
<p>In political science, we usually opt to present predicted probabilities instead of odds ratios, but ultimately you should do whatever you think is best.</p>
</section>
<section id="latent-propensity-representation" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="latent-propensity-representation"><span class="header-section-number">6.5</span> Latent propensity representation</h2>
<p>Sometimes you will see the binary outcome problem represented as a latent propensity where <span class="math inline">\(Y^*_i\)</span> is a continuous variable that represents an unobserved propensity (e.g., to have a dispute, to be a toxic tweet, to participate), where</p>
<span class="math display">\[\begin{gather*}
Y_i = \begin{cases}1, \; y^*_i &gt; \tau \\ 0,\;
y^*_i \leq \tau \end{cases}
\end{gather*}\]</span>
<p>and <span class="math inline">\(\tau\)</span> is some threshold after which a the event (e.g., dispute) occurs.</p>
<p>This becomes particularly relevant when the goal is to classify outcome estimates given certain <span class="math inline">\(X\)</span> features. This type of threshold will also be relevant when we move into ordinal outcome variables where we want to estimate the probability an outcome belongs to a specific category.</p>
</section>
<section id="linear-probability-models" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="linear-probability-models"><span class="header-section-number">6.6</span> Linear Probability Models</h2>
<p>People (who me? yes, I admit, me) will sometimes still use a linear OLS model when we have dichotomous outcomes. In that case, we interpret the results as a “linear probability model” where a one-unit change in <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(\hat \beta\)</span> change in the probability that <span class="math inline">\(Y_i = 1\)</span>.</p>
<p>This may sound like a disaster because linear models are generally meant for nice continuous outcomes, and there is no way to prevent extreme values of <span class="math inline">\(X\beta\)</span> from extending above 1 or below 0. This is not to mention the heteroskedasticity issues that come from binary outcome because the error terms depend on the values of <span class="math inline">\(X\)</span>. This website has a good overview of the potential problems with linear <a href="https://www.dummies.com/education/economics/econometrics/3-main-linear-probability-model-lpm-problems/">regression</a> with binary outcomes.</p>
<p><img src="images/lpmjoke.jpeg" class="img-fluid" style="width:60.0%">\</p>
<p><em>Image from Chelsea Parlett-Pelleriti <span class="citation" data-cites="ChelseaParlett">@ChelseaParlett</span> on Twitter</em></p>
<p>However, we can address some of these potential issues: 1) we can use robust standard errors to account for non-constant error variance , 2) if you look at the S-curve in the previous section, you will note that a large part of the curve is pretty linear over a wide range of <span class="math inline">\(X\beta\)</span> values. For many applications, the estimates transformed from a logit or probit into probability will look similar to the estimates from a linear probability model (i.e., OLS). 3) Linear probability models are easier to interpret, and there is no need to transform coefficients.</p>
<p>LPM vs.&nbsp;logit/probit has spurred a lot of debate throughout the years. Reviewers disagree, twitter users disagree, some people just like to stir the pot, etc. This is just something to be aware of as you choose modeling approaches. Particularly when it comes to experiments and other causal inference approaches, there is a non-trivial push among active scholars to stick with linear probability models when your key independent variable is a discrete treatment indicator variable. See this new <a href="https://psyarxiv.com/4gmbv/">article</a> from Robin Gomilla who lays out the considerations for using LPM, particularly in experimental settings, as well as follow up discussion from <a href="https://statmodeling.stat.columbia.edu/2020/01/10/linear-or-logistic-regression-with-binary-outcomes/">Andrew Gelman</a>. That said, even if you run with an LPM and cite the Gomilla article, a reviewer may still ask you to do a logit/probit. And there are certainly circumstances where LPM will fall short. So what’s the upshot? Probably try both, and then choose your own adventure.</p>
</section>
<section id="binary-models-in-r-tutorial" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="binary-models-in-r-tutorial"><span class="header-section-number">6.7</span> Binary Models in R Tutorial</h2>
<p>This week’s example, we will replicate a portion of “The Effectiveness of a Racialized Counterstrategy” by Antoine Banks and Heather Hicks, <a href="https://onlinelibrary.wiley.com/doi/epdf/10.1111/ajps.12410">published</a> in the <em>American Journal of Political Science</em> in 2018. The replication data are <a href="https://doi.org/10.7910/DVN/EWRXPU">here</a>.</p>
<p><em>Abstract: Our article examines whether a politician charging a political candidate’s implicit racial campaign appeal as racist is an effective political strategy. According to the racial priming theory, this racialized counterstrategy should deactivate racism, thereby decreasing racially conservative whites’ support for the candidate engaged in race baiting. We propose an alternative theory in which racial liberals, and not racially conservative whites, are persuaded by this strategy. To test our theory, we focused on the 2016 presidential election. We ran an experiment varying the politician (by party and race) calling an implicit racial appeal by Donald Trump racist. We find that charging Trump’s campaign appeal as racist does not persuade racially conservative whites to decrease support for Trump. Rather, it causes racially liberal whites to evaluate Trump more unfavorably. Our results hold up when attentiveness, old-fashioned racism, and partisanship are taken into account. We also reproduce our findings in two replication studies.</em></p>
<p>We will replicate the analysis in Table 1 of the paper, based on an experiment the authors conducted through SSI. They exposed white survey respondents to either a news story about a Trump ad that includes an “implicit racial cue” or conditions that add to this with “explicitly racial” responses from different partisan actors calling out the ad as racist. Drawing on racial priming theory, racially prejudiced whites should be less supportive of Trump after the racial cues are made explicit. The authors test this hypothesis against their own hypothesis that this effect should be more pronounced among “racially liberal” whites.</p>
<p><img src="images/implicit.png" class="img-fluid" style="width:45.0%"> <img src="images/explicit.png" class="img-fluid" style="width:38.0%"></p>
<p>We are going to focus on a secondary outcome related to whether respondents believed the ad to be about race: “We also suspect that whites should provide a justification for either maintaining or decreasing their support for the candidate alleged to be playing the race card. Our results support these expectations. For example, racial liberals who read about a politician calling Trump’s implicit ad racist are more likely than those in the implicit condition to believe Trump’s ad is about race. On the other hand, pointing out the racial nature of the ad does not cause resentful whites to be any more likely to believe the ad is about race. Racially resentful whites deny that Trump’s subtle racial appeal on crime is racially motivated, which provides them with the evidence they need to maintain their support for his presidency” (320).</p>
<section id="loading-data-and-fitting-glm" class="level3" data-number="6.7.1">
<h3 data-number="6.7.1" class="anchored" data-anchor-id="loading-data-and-fitting-glm"><span class="header-section-number">6.7.1</span> Loading data and fitting glm</h3>
<p>Let’s load the data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rio)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>study <span class="ot">&lt;-</span> <span class="fu">import</span>(<span class="st">"https://github.com/ktmccabe/teachingdata/blob/main/ssistudyrecode.dta?raw=true"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The data include several key variables</p>
<ul>
<li><code>abtrace1</code>: 1= if the respondent thought the ad was about race. 0= otherwise</li>
<li><code>condition2</code>: 1= respondent in the implicit condition. 2= respondent in one of four explicit racism conditions.</li>
<li><code>racresent</code>: a 0 to 1 numeric variable measuring racial resentment</li>
<li><code>oldfash</code>: a 0 to 1 numeric variable measuring “old-fashioned racism”</li>
<li><code>trumvote</code>: 1= respondent has vote preference for Trump 0=otherwise</li>
</ul>
<p><img src="images/bankstable1.png" class="img-fluid" style="width:75.0%"></p>
<p>Let’s try to replicate column 5 in Table 1 using probit regression, as the authors do.</p>
<ul>
<li>Write down the equation for the regression.</li>
<li>Use <code>glm</code> to run the regression.</li>
<li>Compare the output to the table, column 5.</li>
</ul>
<details>
<summary>
Try on your own, then expand for the solution.
</summary>
<p>We are fitting a probit regression.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Column 5</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>fit.probit5 <span class="ot">&lt;-</span> <span class="fu">glm</span>(abtrace1 <span class="sc">~</span> <span class="fu">factor</span>(condition2)<span class="sc">*</span>racresent <span class="sc">+</span> <span class="fu">factor</span>(condition2)<span class="sc">*</span>oldfash,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">data=</span>study, <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"probit"</span>))</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit.probit5)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
glm(formula = abtrace1 ~ factor(condition2) * racresent + factor(condition2) * 
    oldfash, family = binomial(link = "probit"), data = study)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.2659  -0.9371  -0.5194   1.0015   2.0563  

Coefficients:
                              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)                     0.6320     0.2431   2.600 0.009323 ** 
factor(condition2)2             0.9685     0.2797   3.462 0.000535 ***
racresent                      -1.9206     0.4174  -4.601  4.2e-06 ***
oldfash                         0.5265     0.3907   1.348 0.177772    
factor(condition2)2:racresent  -0.8513     0.4728  -1.801 0.071777 .  
factor(condition2)2:oldfash    -0.4197     0.4376  -0.959 0.337476    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1376.9  on 994  degrees of freedom
Residual deviance: 1148.7  on 989  degrees of freedom
  (25 observations deleted due to missingness)
AIC: 1160.7

Number of Fisher Scoring iterations: 4</code></pre>
</div>
</div>
<p>We can write the regression as: <span class="math display">\[\begin{align*}
Pr(Y_i = 1 | X) &amp;= \\ \Phi(\alpha + \text{Explicit Politician Condition}_i*\beta_1 +\\ \text{Racial Resentment}_i *\beta_2 +\\
\text{Old Fashioned Racism}_i*\beta_3 +\\ \text{Explicit Politician Condition}_i*\text{Racial Resentment}_i*\beta_4 +\\
\text{Explicit Politician Condition}_i* \text{Old Fashioned Racism}_i*\beta_5)
\end{align*}\]</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(equatiomatic)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">extract_eq</span>(fit.probit5, <span class="at">wrap =</span> <span class="cn">TRUE</span>, <span class="at">terms_per_line =</span> <span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><span class="math display">\[
\begin{aligned}
P( \operatorname{abtrace1} = \operatorname{1} ) &amp;= \Phi[\alpha + \beta_{1}(\operatorname{factor(condition2)}_{\operatorname{2}}) + \beta_{2}(\operatorname{racresent})\ + \\
&amp;\qquad\ \beta_{3}(\operatorname{oldfash}) + \beta_{4}(\operatorname{factor(condition2)}_{\operatorname{2}} \times \operatorname{racresent}) + \beta_{5}(\operatorname{factor(condition2)}_{\operatorname{2}} \times \operatorname{oldfash})]
\end{aligned}
\]</span></p>
</div>
</div>
</details>
<p>A few questions:</p>
<ul>
<li>How should we interpret the coefficients?</li>
<li>How do the interactions affect this interpretation?</li>
</ul>
</section>
<section id="numeric-optimization" class="level3" data-number="6.7.2">
<h3 data-number="6.7.2" class="anchored" data-anchor-id="numeric-optimization"><span class="header-section-number">6.7.2</span> Numeric Optimization</h3>
<p>Let’s repeat our replication of column 5, but this time, let’s use numeric optimization. We first need to make an X and Y matrix from our data. Because we have already run the models, let’s use a trick below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(fit.probit5)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(fit.probit5<span class="sc">$</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The next thing we need to do is make a function for the log likelihood. Let’s recall the log likelihood for a Bernoulli random variable from a previous section:</p>
<span class="math display">\[\begin{align*}
\mathcal L( \pi | Y_i) &amp;= \underbrace{\pi^{y_i}(1 -\pi)^{(1-y_i)}}_\text{Likelihood for single observation}\\
\mathcal L( \pi | Y) &amp;= \underbrace{\prod_{i=1}^n\pi^{y_i}(1 -\pi)^{(1-y_i)}}_\text{Likelihood for all observations}\\
\ell( \pi | Y) &amp;= \underbrace{\sum_{i=1}^n\log \pi^{y_i}(1 -\pi)^{(1-y_i)}}_\text{Log likelihood}
\end{align*}\]</span>
<p>Now we just change the definition of <span class="math inline">\(\pi\)</span> to be the transformation for a probit, which is <span class="math inline">\(\Phi(X\beta)\)</span>. We code this up as a function below. Try to make the connection between the log likelihood equation above and the last line of the function. Note: in R, we can use <code>pnorm()</code> to express <span class="math inline">\(\Phi(X\beta)\)</span>, this is the CDF of the normal distribution.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>llik.probit <span class="ot">&lt;-</span> <span class="cf">function</span>(par, Y, X){</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  beta <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(par)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  link <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(X <span class="sc">%*%</span> beta)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>  like <span class="ot">&lt;-</span> <span class="fu">sum</span>(Y<span class="sc">*</span><span class="fu">log</span>(link) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> Y)<span class="sc">*</span><span class="fu">log</span>(<span class="dv">1</span> <span class="sc">-</span> link))</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(like)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s generate some starting values for the optimization.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Starting values</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>ls.lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X[, <span class="sc">-</span><span class="dv">1</span>]) </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>start.par <span class="ot">&lt;-</span> ls.lm<span class="sc">$</span>coef</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, let’s use <code>optim</code> to find our parameter estimates.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="do">## optim()</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>out.opt <span class="ot">&lt;-</span> <span class="fu">optim</span>(start.par, llik.probit, <span class="at">Y=</span>Y,</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">X=</span>X, <span class="at">control=</span><span class="fu">list</span>(<span class="at">fnscale=</span><span class="sc">-</span><span class="dv">1</span>), <span class="at">method=</span><span class="st">"BFGS"</span>,</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">hessian =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can compare the estimates recovered from <code>glm</code> and <code>optim</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Log likelihood</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(fit.probit5)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>out.opt<span class="sc">$</span>value</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'log Lik.' -574.3267 (df=6)
[1] -574.3267</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Coefficients</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind</span>(<span class="fu">round</span>(<span class="fu">coef</span>(fit.probit5), <span class="at">digits=</span><span class="dv">4</span>),</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(out.opt<span class="sc">$</span>par, <span class="at">digits =</span> <span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                                 [,1]    [,2]
(Intercept)                    0.6320  0.6321
factor(condition2)2            0.9685  0.9684
racresent                     -1.9206 -1.9207
oldfash                        0.5265  0.5265
factor(condition2)2:racresent -0.8513 -0.8512
factor(condition2)2:oldfash   -0.4197 -0.4196</code></pre>
</div>
</div>
<p>How could we get the standard errors?</p>
</section>
<section id="predicted-probabilities" class="level3" data-number="6.7.3">
<h3 data-number="6.7.3" class="anchored" data-anchor-id="predicted-probabilities"><span class="header-section-number">6.7.3</span> Predicted Probabilities</h3>
<p>One thing we could do for our interpretations is to push this further to generate “quantities of interest.”</p>
<p><img src="images/abtracefig.png" class="img-fluid" style="width:70.0%"></p>
<p>We will do one example of this but will talk in more detail about this next week. Let’s generate predicted probabilities for thinking the ad is about race across levels of racial resentment in the sample, for people in the implicit and explicit conditions. For this example, we are going to hold “old-fashioned racism” at its mean value. This is slightly different from what the authors do but should generate similar results. The authors hold old-fashioned racism at its “observed values.”</p>
<p>We can rely on the <code>predict</code> function like we did with OLS, but here, we need to set <code>type = response</code> to put the results on the response scale instead of the scale of the linear predictor. What this does is apply our function <span class="math inline">\(\Phi(\mathbf{x_i}' \hat \beta)\)</span> for our designated values of <span class="math inline">\(X\)</span> and estimates for <span class="math inline">\(\hat \beta\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>predvals.imp <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit.probit5, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">condition2=</span><span class="dv">1</span>, </span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>                                                         <span class="at">racresent =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">0625</span>),</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>                                         <span class="at">oldfash =</span> <span class="fu">mean</span>(study<span class="sc">$</span>oldfash, <span class="at">na.rm=</span>T)),</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>                    <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>predvals.exp <span class="ot">&lt;-</span> <span class="fu">predict</span>(fit.probit5, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">condition2=</span><span class="dv">2</span>,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>                                                         <span class="at">racresent =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>,.<span class="dv">0625</span>),</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>                                         <span class="at">oldfash =</span> <span class="fu">mean</span>(study<span class="sc">$</span>oldfash, <span class="at">na.rm=</span>T)),</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>                    <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot results</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">x=</span><span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">0625</span>), <span class="at">y=</span>predvals.imp, <span class="at">type=</span><span class="st">"l"</span>,</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">lty=</span><span class="dv">2</span>,</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Predicted Probability"</span>,</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Racial Resentment"</span>,</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Predicted Probability of Viewing the Ad as about Race"</span>,</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>     <span class="at">cex.main =</span> .<span class="dv">7</span>)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"bottomleft"</span>, <span class="at">lty=</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="fu">c</span>(<span class="st">"Implicit"</span>, <span class="st">"Explicit"</span>))</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="at">x=</span><span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, .<span class="dv">0625</span>), <span class="at">y=</span>predvals.exp, <span class="at">type=</span><span class="st">"l"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="06-BinaryOutcomes_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><em>Additional Questions</em></p>
<ul>
<li>For extra practice, you can try replicating column 4 in the model.</li>
<li>You can also try replicating the results in the figure with a logit model. Are the predicted probabilities similar?</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./05-IntrotoMaximumLikelihood.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to MLE</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./07-QuantitiesofInterest.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Quantities of Interest</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>