toydata <- data.frame(x = 1:8, y = seq(2, 20, length = 8),
upper=seq(4, 24, length = 8),
lower=seq(0, 16, length = 8))
ggplot(toydata) +
geom_line(aes(x, y )) +
geom_ribbon(aes(x=1:8, ymax = upper ,
ymin = lower), fill = "light blue", alpha = .3)
# Chunk 8
## Example using plot
p.logit <- predict(fit.logit, newdata = data.frame(left_right = 1:7),type = "response", se = T)
p.logit <- predict(fit.logit, newdata = data.frame(left_right = 1:7),type = "response", se = T)
p.probit <- predict(fit.probit, newdata = data.frame(left_right = 1:7), type = "response", se = T)
p.lm <- predict(fit.lm, newdata = data.frame(left_right = 1:7), interval = "confidence")
p.logit.l <- predict(fit.logit, newdata = data.frame(left_right = 1:7),type = "link", se = T)
p.logit.ub <- plogis(p.logit.l$fit + qnorm(.975)*p.logit.l$se.fit)
p.logit.lb <- plogis(p.logit.l$fit - qnorm(.975)*p.logit.l$se.fit)
cbind(p.logit$fit, p.logit.lb, p.logit.ub)
p.probit.l <- predict(fit.probit, newdata = data.frame(left_right = 1:7), type = "link", se = T)
p.probit.ub <- pnorm(p.probit.l$fit + qnorm(.975)*p.probit.l$se.fit)
p.probit.lb <- pnorm(p.probit.l$fit - qnorm(.975)*p.probit.l$se.fit)
library(marginaleffects)
me.predictions <- predictions(fit.logit,newdata = datagrid(left_right = 1:7))
library(prediction)
summary(prediction(fit.logit, at = list(left_right = 1:7), calculate_se=T))
pdf("mymultip.pdf", width = 12, height = 5)
par(mfrow = c(1, 3))
plot(1:7, p.lm[, 1], ylim = c(0, 1),
main = "Predicted Probability of Cooperation by Ideology \n Linear Probability",
ylab = "Predicted Probability",
xlab = "Left-Right Ideology", type = "b", pch = 20,
cex.main = .8)
lines(1:7, p.lm[, 2])
lines(1:7, p.lm[, 3])
plot(1:7, p.logit$fit, ylim = c(0, 1),
main = "Predicted Probability of Cooperation by Ideology \n Logistic Regression",
ylab = "Predicted Probability",
xlab = "Left-Right Ideology", type = "b", pch = 20,
cex.main = .8)
lines(1:7, p.logit.ub)
lines(1:7, p.logit.lb)
plot(1:7, p.probit$fit, ylim = c(0, 1),
main = "Predicted Probability of Cooperation by Ideology \n Probit Regression",
ylab = "Predicted Probability",
xlab = "Left-Right Ideology", type = "b", pch = 20,
cex.main = .8)
lines(1:7, p.probit.ub)
lines(1:7, p.probit.lb)
dev.off()
# Chunk 9
## Example using ggplot
library(ggplot2)
g1 <- ggplot() +
geom_line(aes(x = 1:7, y = p.lm[, 1] )) +
geom_ribbon(aes(x=1:7, ymax = p.lm[,3], ymin = p.lm[,2]), fill = "light blue", alpha = .3) +
labs(y = "Predicted Probability", x = "Left-Right Ideology") +
ggtitle("Predicted Probability of Cooperation \n Linear Regression") +
ylim(0, 1) +
xlim(1, 7)+
theme(plot.title = element_text(hjust = 0.5)) # centers the title
g2 <- ggplot() +
geom_line(aes(x = 1:7, y = p.logit$fit)) +
geom_ribbon(aes(x=1:7, ymax = p.logit.ub, ymin = p.logit.lb), fill = "light blue", alpha = .3) +
labs(y = "Predicted Probability", x = "Left-Right Ideology") +
ggtitle("Predicted Probability of Cooperation \n Logit Regression") +
ylim(0, 1) +
xlim(1, 7)+
theme(plot.title = element_text(hjust = 0.5)) # centers the title
g3 <- ggplot() +
geom_line(aes(x = 1:7, y = p.probit$fit)) +
geom_ribbon(aes(x=1:7, ymax = p.probit.ub, ymin = p.probit.lb), fill = "light blue", alpha = .3) +
labs(y = "Predicted Probability", x = "Left-Right Ideology") +
ggtitle("Predicted Probability of Cooperation \n Probit Regression") +
ylim(0, 1) +
xlim(1, 7)+
theme(plot.title = element_text(hjust = 0.5)) # centers the title
library(gridExtra)
grid.arrange(g1, g2, g3, ncol=3)
# Chunk 1
knitr::opts_chunk$set(echo = TRUE,  size='footnotesize')
knitr::opts_knit$set(root.dir = "/Users/ktmccabe/Dropbox/figs/")
# Chunk 2
load("data.analysis.RData")
exc <- x
## observations
nrow(exc)
## one approach
library(tidyverse)
exc %>%
mutate(arab_coop_num = as.numeric(arab_coop) - 1) %>%
summarise(mean(arab_coop_num, na.rm=T))
## another approach
exc$arab_coop <- as.numeric(as.character(exc$arab_coop))
mean(exc$arab_coop)
# Chunk 3
fit.logit <- glm(arab_coop ~ left_right,
data=exc, family=binomial(link = "logit"))
coef(fit.logit)[2]
fit.probit <- glm(arab_coop ~ left_right,
data=exc, family=binomial(link = "probit"))
coef(fit.probit)[2]
fit.lm <- lm(arab_coop ~ left_right, data = exc)
coef(fit.lm)[2]
predvals.log.link <- predict(fit.logit, newdata = data.frame(left_right = seq(1, 7, 1),
na.rm=T),
type="link",
se = T)
predvals.log.link$fit
# Chunk 6
## toy example of a plot with lines using fake data.
## Your plot does not have to look like this.
## Many ways to code. Feel free to be creative
toydata <- data.frame(x = 1:8, y = seq(2, 20, length = 8),
upper=seq(4, 24, length = 8),
lower=seq(0, 16, length = 8))
plot(toydata$x, toydata$y,
type = "l")
points(toydata$x, toydata$upper, lty = 2, type="l")
points(toydata$x, toydata$lower, lty = 2, type ="l")
# Chunk 7
## toy example of a ggplot with lines using fake data.
## Your plot does not have to look like this.
## Many ways to code. Feel free to be creative
library(ggplot2)
toydata <- data.frame(x = 1:8, y = seq(2, 20, length = 8),
upper=seq(4, 24, length = 8),
lower=seq(0, 16, length = 8))
ggplot(toydata) +
geom_line(aes(x, y )) +
geom_ribbon(aes(x=1:8, ymax = upper ,
ymin = lower), fill = "light blue", alpha = .3)
# Chunk 8
## Example using plot
p.logit <- predict(fit.logit, newdata = data.frame(left_right = 1:7),type = "response", se = T)
p.logit <- predict(fit.logit, newdata = data.frame(left_right = 1:7),type = "response", se = T)
p.probit <- predict(fit.probit, newdata = data.frame(left_right = 1:7), type = "response", se = T)
p.lm <- predict(fit.lm, newdata = data.frame(left_right = 1:7), interval = "confidence")
p.logit.l <- predict(fit.logit, newdata = data.frame(left_right = 1:7),type = "link", se = T)
p.logit.ub <- plogis(p.logit.l$fit + qnorm(.975)*p.logit.l$se.fit)
p.logit.lb <- plogis(p.logit.l$fit - qnorm(.975)*p.logit.l$se.fit)
cbind(p.logit$fit, p.logit.lb, p.logit.ub)
p.probit.l <- predict(fit.probit, newdata = data.frame(left_right = 1:7), type = "link", se = T)
p.probit.ub <- pnorm(p.probit.l$fit + qnorm(.975)*p.probit.l$se.fit)
p.probit.lb <- pnorm(p.probit.l$fit - qnorm(.975)*p.probit.l$se.fit)
library(marginaleffects)
me.predictions <- predictions(fit.logit,newdata = datagrid(left_right = 1:7))
library(prediction)
summary(prediction(fit.logit, at = list(left_right = 1:7), calculate_se=T))
pdf("mymultip.pdf", width = 12, height = 5)
par(mfrow = c(1, 3))
plot(1:7, p.lm[, 1], ylim = c(0, 1),
main = "Predicted Probability of Cooperation by Ideology \n Linear Probability",
ylab = "Predicted Probability",
xlab = "Left-Right Ideology", type = "b", pch = 20,
cex.main = .8)
lines(1:7, p.lm[, 2])
lines(1:7, p.lm[, 3])
plot(1:7, p.logit$fit, ylim = c(0, 1),
main = "Predicted Probability of Cooperation by Ideology \n Logistic Regression",
ylab = "Predicted Probability",
xlab = "Left-Right Ideology", type = "b", pch = 20,
cex.main = .8)
lines(1:7, p.logit.ub)
lines(1:7, p.logit.lb)
plot(1:7, p.probit$fit, ylim = c(0, 1),
main = "Predicted Probability of Cooperation by Ideology \n Probit Regression",
ylab = "Predicted Probability",
xlab = "Left-Right Ideology", type = "b", pch = 20,
cex.main = .8)
lines(1:7, p.probit.ub)
lines(1:7, p.probit.lb)
dev.off()
# Chunk 9
## Example using ggplot
library(ggplot2)
g1 <- ggplot() +
geom_line(aes(x = 1:7, y = p.lm[, 1] )) +
geom_ribbon(aes(x=1:7, ymax = p.lm[,3], ymin = p.lm[,2]), fill = "light blue", alpha = .3) +
labs(y = "Predicted Probability", x = "Left-Right Ideology") +
ggtitle("Predicted Probability of Cooperation \n Linear Regression") +
ylim(0, 1) +
xlim(1, 7)+
theme(plot.title = element_text(hjust = 0.5)) # centers the title
g2 <- ggplot() +
geom_line(aes(x = 1:7, y = p.logit$fit)) +
geom_ribbon(aes(x=1:7, ymax = p.logit.ub, ymin = p.logit.lb), fill = "light blue", alpha = .3) +
labs(y = "Predicted Probability", x = "Left-Right Ideology") +
ggtitle("Predicted Probability of Cooperation \n Logit Regression") +
ylim(0, 1) +
xlim(1, 7)+
theme(plot.title = element_text(hjust = 0.5)) # centers the title
g3 <- ggplot() +
geom_line(aes(x = 1:7, y = p.probit$fit)) +
geom_ribbon(aes(x=1:7, ymax = p.probit.ub, ymin = p.probit.lb), fill = "light blue", alpha = .3) +
labs(y = "Predicted Probability", x = "Left-Right Ideology") +
ggtitle("Predicted Probability of Cooperation \n Probit Regression") +
ylim(0, 1) +
xlim(1, 7)+
theme(plot.title = element_text(hjust = 0.5)) # centers the title
library(gridExtra)
grid.arrange(g1, g2, g3, ncol=3)
# Chunk 10
fit.4 <- glm(arab_coop ~ arab_reject_binary +  left_right +  arab_reject_binary*left_right,
data=exc, family=binomial(link="probit"))
summary(fit.4)
## could do a separate predict for each combination
predict(fit.4, newdata = data.frame(arab_reject_binary = 0, left_right=1),
type="response")
## OR combining using expand.grid, which finds each combination
ps <- expand.grid(arab_reject_binary = c(0,1), left_right = c(1, 7))
predict(fit.4, ps, type = "response")
## One approach with predictions
predictions(fit.4, by="left_right",
newdata=datagrid(arab_reject_binary=0,
left_right = c(1, 7)))
predictions(fit.4, by="left_right",
newdata=datagrid(arab_reject_binary=1,
left_right = c(1, 7)))
## Second approach with predictions
## (apparently it will also accept a new dataframe using expand grid)
predictions(fit.4, by=c("arab_reject_binary", "left_right"),
newdata=expand.grid(arab_reject_binary = c(0,1), left_right = c(1, 7)))
# Chunk 11
fit.2 <- glm(arab_coop ~ arab_reject_binary + age +
foreign_born + sex + left_right +
as.factor(religiosity) + as.factor(education) + as.factor(income)+ as.factor(ethnicity),
data=exc, family=binomial)
## a
coef(fit.2)[2]
## b
sd1 <- model.matrix(fit.2)
sd1[, "arab_reject_binary"] <- 1
p1 <- mean(plogis(sd1 %*% coef(fit.2)))
p1
## c
sd0 <- model.matrix(fit.2)
sd0[, "arab_reject_binary"] <- 0
p0 <- mean(plogis(sd0 %*% coef(fit.2)))
p0
## d
p1 - p0
## compare with predictions
avg_predictions(fit.2, type="response",
by="arab_reject_binary",
newdata=datagridcf(arab_reject_binary = c(0,1)))
## compare with marginal effects
avg_comparisons(fit.2, type="response",
variables = list(arab_reject_binary=c(0,1)))
library(prediction)
library(margins)
summary(prediction(fit.2, at=list(arab_reject_binary=c(0,1))))
summary(margins(fit.2, variables="arab_reject_binary",
change=c(0,1)))
## bootstrap
my.boot <- function(df){
wrows <- sample(1:nrow(df), nrow(df), replace = T) # pick some rows
subdata <- df[wrows, ] # create new data frame with these rows
fit.sub <- glm(arab_coop ~ arab_reject_binary + age +
foreign_born + sex + left_right +
as.factor(religiosity) + as.factor(education) + as.factor(income) + as.factor(ethnicity),
data=subdata, family=binomial) # run glm on this new subset
f1 <- model.matrix(fit.sub)
f1[, "arab_reject_binary"] <- 1
m1 <- mean(plogis(f1 %*% coef(fit.sub)))
f0 <- model.matrix(fit.sub)
f0[, "arab_reject_binary"] <- 0
m0 <- mean(plogis(f0 %*% coef(fit.sub)))
estimatesv <- m1-m0
return(estimatesv)}
set.seed(1234)
estimates.v <- replicate(1000, my.boot(exc))
## bias corrected
estimates.corr <- 2*(p1 - p0) - estimates.v
## results
c((p1 - p0), quantile(estimates.corr, c(.025, .975)))
c((p1 - p0), quantile(estimates.v, c(.025, .975)))
## d, quasi bayesian
library(mvtnorm)
qestimates <- rep(NA, 1500)
set.seed(1234)
qb.beta <- rmvnorm(1500, coef(fit.2), vcov(fit.2))
dim(qb.beta) # 1500 x 19
for(i in 1:1500){
qestimates[i] <- mean(plogis(sd1 %*% qb.beta[i,]) - plogis(sd0 %*% qb.beta[i,]))
}
## results
c((p1 - p0), quantile(qestimates, c(.025, .975)))
# Chunk 12
llik.logit <- function(par, Y, X){
beta <- as.matrix(par)
lt <- exp(X %*% beta) / (1 + exp(X %*% beta))
return(sum(Y*log(lt) + (1 - Y)*log(1 - lt)))
}
## bo starting values
myd <- cbind(exc$arab_coop, exc$arab_reject_binary, exc$trust.b)
myd <- na.omit(myd)
fitlm <- lm(myd[, 1] ~ myd[, 2] + myd[, 3])
start.par <- coef(fitlm)
Y <- myd[, 1]
X <- cbind(1, myd[, 2], myd[, 3])
b0 <- coef(fitlm)
## Optim
opt.out <- optim(par=start.par, fn=llik.logit,X=X, Y=Y, method="BFGS",
control=list(fnscale=-1))
opt.out$par
## Newton function
my.newton <- function(b0, Y, X, ep){
while(ep > .0000001){
ll0 <- llik.logit(b0, Y, X)
pi <- exp(X %*% b0)/( 1 + exp(X %*% b0))
score <- t(X) %*% (Y - pi)
H <- -t(X) %*% diag(as.numeric(pi)) %*% (X)
b0 <- b0 - solve(H)%*%score
lln <- llik.logit(b0, Y, X)
ep <- lln - ll0
}
return(b0)
}
my.newton(start.par, as.matrix(Y), X, 4)
fit.1 <- glm(arab_coop ~ arab_reject_binary + trust.b,
data=exc, family=binomial(link = "logit"))
coef(fit.1)
table(exc$left_right)
logit.me <-avg_predictions(fit.logit, type="response", by="left_right")
logit.me
logit.me <-avg_predictions(fit.logit, type="response", by="left_right",
newdata=datagridcf(left_right=1:7))
logit.me
p.probit <- predict(fit.probit, newdata = data.frame(left_right = 1:7), type = "response", se = T)
p.probit
llik.logit <- function(par, Y, X){
beta <- as.matrix(par)
lt <- plogis(X%*% beta)
#lt <- exp(X %*% beta) / (1 + exp(X %*% beta))
return(sum(Y*log(lt) + (1 - Y)*log(1 - lt)))
}
myd <- cbind(exc$arab_coop, exc$arab_reject_binary, exc$trust.b)
myd <- na.omit(myd)
fitlm <- lm(myd[, 1] ~ myd[, 2] + myd[, 3])
start.par <- coef(fitlm)
Y <- myd[, 1]
X <- cbind(1, myd[, 2], myd[, 3])
b0 <- coef(fitlm)
## Optim
opt.out <- optim(par=start.par, fn=llik.logit,X=X, Y=Y, method="BFGS",
control=list(fnscale=-1))
opt.out$value
opt.out$par
fit.1 <- glm(arab_coop ~ arab_reject_binary + trust.b,
data=exc, family=binomial(link = "logit"))
coef(fit.1)
summary(fit.1)
summary(fit.2)
predict(fit.4, newdata = data.frame(arab_reject_binary = 0, left_right=1),
type="link")
library(foreign)
emp <- read.dta("https://github.com/ktmccabe/teachingdata/blob/main/week6.dta?raw=true")
emp$outfav <- as.factor(emp$outfav)
table(emp$outfav)
class(emp$outfav)
library(survey)
empd <- svydesign(ids=~1, weights = emp$weight_group, data=emp)
fit.empw2 <- svyolr(outfav ~ empconc + empdist + emppers + empfant +
+ pidext + ideoext + news + dem +
as.numeric(educ) + age +
male + white + factor(inc3miss),
design=empd, method="logistic")
summary(fit.empw2)
X <- model.matrix(fit.empw2)
X <- X[, -1] #remove intercept
X[,"empconc" ] <- 0
# Find Xb and zeta
coef(fit.empw2)
# this piece [1:ncol(X)] makes sure we omit the zetas
# this is only necessary for svyolr. The polr function already omits zetas from coef()
b <- coef(fit.empw2)[1:ncol(X)]
eta <- X %*% b
zeta <- fit.empw2$zeta
## Find Pr(lowest category)
emp0 <- mean(plogis(zeta[1] - eta))
emp0
## Repeat for each value of empconc of interest
X[,"empconc"] <- .2
# Find Xb and zeta
eta <- X %*% coef(fit.empw2)[1:ncol(X)]
zeta <- fit.empw2$zeta
## Find Pr(lowest category)
emp2 <- mean(plogis(zeta[1] - eta))
emp2
findpr <- function(val){
X[,"empconc"] <- val
# Find Xb and zeta
eta <- X %*% coef(fit.empw2)[1:ncol(X)]
zeta <- fit.empw2$zeta
## Find Pr(lowest category)
pr <- mean(plogis(zeta[1] - eta))
return(pr)
}
## Does it work? Test
findpr(0)
## Repeat for all values of empathy
emp.prs <- sapply(seq(0, 1, .2), findpr)
emp.prs
library(marginaleffects)
library(marginaleffects)
pe.all <- avg_predictions(fit.empw2, by="empconc",
datagridcf(empconc = seq(0, 1, .2)))
X <- model.matrix(fit.empw2)
X <- X[, -1] #remove intercept
X[,"empconc" ] <- 0
# Find Xb and zeta
coef(fit.empw2)
# this piece [1:ncol(X)] makes sure we omit the zetas
# this is only necessary for svyolr. The polr function already omits zetas from coef()
b <- coef(fit.empw2)[1:ncol(X)]
eta <- X %*% b
zeta <- fit.empw2$zeta
## Find Pr(lowest category)
emp0 <- mean(plogis(zeta[1] - eta))
emp0
table(emp$outfav)
library(foreign)
emp <- read.dta("https://github.com/ktmccabe/teachingdata/blob/main/week6.dta?raw=true")
table(emp$outfav)
class(emp$outfav)
table(emp$empconc)
fit <- lm(outfav ~ empconc, data=emp)
summary(fit)
table(emp$empconc) # empathic concern, from low to high
class(emp$outfav) # how favorable you view the outparty
table(emp$outfav)
emp$outfav <- as.factor(emp$outfav)
class(emp$outfav)
library(MASS)
library(MASS)
fit.logit <- polr(outfav ~ empconc, data=emp, Hess = T,
method="logistic")
summary(fit.logit)
fit.logit <- polr(outfav ~ empconc, data=emp, Hess = F,
method="logistic")
summary(fit.logit)
fit.logit <- polr(outfav ~ empconc, data=emp, Hess = TRUE,
method="logistic")
summary(fit.logit)
?polr
library(survey)
empd <- svydesign(ids=~1, weights = emp$weight_group, data=emp)
fit.empw2 <- svyolr(outfav ~ empconc + empdist + emppers + empfant +
+ pidext + ideoext + news + dem +
as.numeric(educ) + age +
male + white + factor(inc3miss),
design=empd, method="logistic")
summary(fit.empw2)
fit.empw2 <- svyolr(outfav ~ empconc + empdist + emppers + empfant +
+ pidext + ideoext + news + dem +
as.numeric(educ) + age +
male + white + factor(inc3miss),
design=empd, method="logistic")
summary(fit.empw2)
fit.empw2$df.residual
coeftest(fit.empw2)
library(AER)
coeftest(fit.empw2)
round(2*pnorm(abs(summary(fit.empw2)$coefficients[,3]),
lower.tail = F), digits=6)
pvals.empw2 <- round(2*pnorm(abs(summary(fit.empw2)$coefficients[,3]),
lower.tail = F), digits=6)
pvals.empw2[1]
coeftest(fit.empw2)
?pt
pvals.empw2.t <- round(2*pt(abs(summary(fit.empw2)$coefficients[,3]),
lower.tail = F), digits=6, df=fit.empw2$df.residual)
pvals.empw2.t <- pt(abs(summary(fit.empw2)$coefficients[,3]),
lower.tail = F)
pvals.empw2.t <- pt(abs(summary(fit.empw2)$coefficients[,3]),
lower.tail = F, df= fit.empw2$df.residual)
pvals.empw2.t[1]
pvals.empw2 <- 2*pnorm(abs(summary(fit.empw2)$coefficients[,3]),
lower.tail = F)
pvals.empw2[1]
fit.empw2$df.residual
pvals.empw2.t <- pt(abs(summary(fit.empw2)$coefficients[,3]),
lower.tail = F, df= 7000)
pvals.empw2.t[1]
pvals.empw2 <- 2*pnorm(abs(summary(fit.empw2)$coefficients[,3]),
lower.tail = F)
pvals.empw2[1]
library(AER)
coeftest(fit.empw2)
## Set covariates to particular values (here, we hold at observed)
X <- model.matrix(fit.empw2)
X <- X[, -1] #remove intercept
X[,"empconc" ] <- 0
# Find Xb and zeta
coef(fit.empw2)
# Find Xb and zeta
coef(fit.empw2)
ncol(X)
ncol(X)
coef(fit.empw2)[1:ncol(X)]
b <- coef(fit.empw2)[1:ncol(X)]
b <- coef(fit.empw2)[1:ncol(X)]
eta <- X %*% b
zeta <- fit.empw2$zeta
b <- coef(fit.empw2)[1:ncol(X)]
eta <- X %*% b
zeta <- fit.empw2$zeta
emp0 <- mean(plogis(zeta[1] - eta))
emp0
setwd("/Users/ktmccabe/Dropbox/Rutgers Teaching/data science for politics/fall2023/finalprojectdata/Kaiser2023")
knitr::opts_chunk$set(echo = TRUE)
kff23 <- read.csv("KFFSept23.csv")
head(kff23)
